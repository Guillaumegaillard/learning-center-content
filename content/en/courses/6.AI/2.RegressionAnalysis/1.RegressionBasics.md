---
title: General introduction to Regression Analysis
---

In this lesson, we'll learn the basics about regression analysis.

{{< table-of-contents >}}

# Regression Analysis

## General Introduction to Regression Analysis

Regression analysis is a basic concept of machine learning. With help of regression continuos values can be predicted. It is used to plot a best-fit line or a curve between data and can give a hint about the future development of data. It is a supervised learning method, that means the model is trained with help of training data and labels.

## Variables

In regression analysis a set of statistical methods is used to estimate relationships between a dependent and one or more independent variables.

- dependent variables: variable which holds the phenomena which we are studying, is dependent on other variables or factors, changes when independent variables change
- independent variables: the variables that are not affected by other variables

### Example on dependent and independent variables



## Important Metrics

In the following the important metrics like variance, bias, r2-score and mean square error (MSE) are explained. Machine learning algorithms use statistical or mathematical models. They have inherent errors in two categories:

- irreducible errors: inherent uncertainty, due to noise in training data due to unknown variables
- reducible errors: more controllable, should be minimized to ensure higher accuracy: variance and Bias

So the error in a machine learning model is made up of:
<p style="text-align: center;">
<img src="https://latex.codecogs.com/svg.image?Error = Reducible Error + Irreducible Error">
</p>

The reducible Error is the sum of squared Bias and Variance.
<p style="text-align: center;">
<img src="https://latex.codecogs.com/svg.image?Reducible Error = Bias^2 + Variance">
</p>

Combining the above two equations, we get:
<p style="text-align: center;">
<img src="https://latex.codecogs.com/svg.image?Error = Bias^2 + Variance + Irreducible Error">
</p>

### Variance

Also known as **Variance Error** or **Error due to Variance**. Variance measures how close observed values are to predicted values or, in other words, how far observed values are spread out from the their mean (predicted) values. The goal is here to have a low value, this means the prediction is accurate compared to the observed values. 
It shows the amount of the target's functions change, if different training data is introduced.

### Bias

Bias is a constant or vector that shows the difference of the model's prediction from the target value. In other words, it is the simplifying assumption made by the model to make the target function easier to approximate. 

### R2-Score

Todo

### Mean Square Error

Todo






